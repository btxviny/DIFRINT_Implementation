{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VINY\\anaconda3\\envs\\cv\\Lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2, os , random\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from time import sleep\n",
    "\n",
    "h,w = (256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameGenerator:\n",
    "    def __init__(self, path , shape):\n",
    "        self.path = path\n",
    "        self.shape = shape\n",
    "        self.folder_paths = []\n",
    "    def __call__(self):\n",
    "        if not self.folder_paths:\n",
    "            for root, _, _ in os.walk(self.path):\n",
    "                self.folder_paths.append(root)\n",
    "        \n",
    "        random.shuffle(self.folder_paths)\n",
    "        \n",
    "        for folder_path in self.folder_paths:\n",
    "            _, _, files = next(os.walk(folder_path))\n",
    "            files.sort()  # Sort files in ascending order\n",
    "            for i in range(1, len(files) - 1):\n",
    "                frame_t_minus_1 = os.path.join(folder_path, files[i-1])\n",
    "                frame_t = os.path.join(folder_path, files[i])\n",
    "                frame_t_plus_1 = os.path.join(folder_path, files[i+1])\n",
    "                \n",
    "                ft_minus = cv2.imread(frame_t_minus_1)\n",
    "                ft_minus = cv2.resize(ft_minus, (self.shape[1],self.shape[0]))\n",
    "                fi = cv2.imread(frame_t)\n",
    "                fi = cv2.resize(fi, (self.shape[1],self.shape[0]))\n",
    "                ft_plus = cv2.imread(frame_t_plus_1)\n",
    "                ft_plus = cv2.resize(ft_plus, (self.shape[1],self.shape[0]))\n",
    "                fs = random_translation(fi)\n",
    "                yield ft_minus, fi, fs, ft_plus\n",
    "\n",
    "\n",
    "def random_translation(img):\n",
    "    (h,w) = img.shape[:-1]\n",
    "    dx = np.random.randint(-w//8,w//8)\n",
    "    dy = np.random.randint(-h//8,h//8)\n",
    "    mat = np.array([[1,0,dx],[0,1,dy]],dtype=np.float32)\n",
    "    return cv2.warpAffine(img, mat, (w,h))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](Screenshot_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version:  2.12.0\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, None, None,   0           ['input_1[0][0]',                \n",
      "                                6)                                'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, None, None,   0           ['input_4[0][0]',                \n",
      "                                6)                                'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " pwc (PWC)                      (None, None, None,   9374274     ['concatenate[0][0]',            \n",
      "                                3)                                'concatenate_1[0][0]',          \n",
      "                                                                  'concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, None, None,   0           ['pwc[0][0]',                    \n",
      "                                6)                                'pwc[1][0]']                    \n",
      "                                                                                                  \n",
      " u_net (UNet)                   (None, None, None,   448582      ['concatenate_2[0][0]']          \n",
      "                                3)                                                                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, None, None,   0           ['input_3[0][0]',                \n",
      "                                6)                                'u_net[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, None, None,   0           ['pwc[2][0]',                    \n",
      "                                6)                                'u_net[0][0]']                  \n",
      "                                                                                                  \n",
      " res_net (ResNet)               (None, None, None,   111860      ['concatenate_4[0][0]']          \n",
      "                                3)                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,934,716\n",
      "Trainable params: 559,656\n",
      "Non-trainable params: 9,375,060\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from models.models import PWC, UNet, ResNet\n",
    "from tensorflow.keras.layers import Input ,Concatenate\n",
    "#sub_models\n",
    "pwc = PWC()\n",
    "pwc(tf.zeros((1,h,w,6))) # pass a dummy input to build and load weights \n",
    "#freeze paramaters of pwc\n",
    "for layer in pwc.layers:\n",
    "    layer.trainable = False\n",
    "unet = UNet()\n",
    "resnet = ResNet()\n",
    "#inputs\n",
    "f1 = Input((None,None,3)) #previous frame\n",
    "fs = Input((None,None,3)) #pseudo ground truth\n",
    "fi = Input((None,None,3)) #original frame\n",
    "f2 = Input((None,None,3)) #next frame\n",
    "#preparing input for pwc\n",
    "f1s = Concatenate(axis=-1)([f1,fs]) #concatenated f1,fs resulting in 6 channels\n",
    "f2s = Concatenate(axis=-1)([f2,fs]) #concatenated f2,fs resulting in 6 channels\n",
    "#forward through pwc\n",
    "fw_minus = pwc(f1s)  #3 channels\n",
    "fw_plus = pwc(f2s)   #3 channels\n",
    "#preparing input for unet\n",
    "fw = Concatenate(axis=-1)([fw_minus,fw_plus])\n",
    "#forward through unet\n",
    "fint = unet(fw)\n",
    "#preparing input for pwc (warping fi to fint)\n",
    "fiint = Concatenate(axis=-1)([fi,fint])\n",
    "warped = pwc(fiint)\n",
    "#concatenating the warped and interpolated frame for input to resnet\n",
    "fr = Concatenate(axis=-1)([warped,fint])\n",
    "fout = resnet(fr) \n",
    "\n",
    "#defining the entire model\n",
    "difrint = tf.keras.Model([f1,fs,fi,f2],[fint,fout])\n",
    "difrint.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "vgg = VGG19(include_top = False, weights='imagenet')\n",
    "\n",
    "#optimizers\n",
    "optimizer = tf.keras.optimizers.Adam(beta_1=0.9, beta_2=0.999,learning_rate=1e-3)\n",
    "u_optimizer = tf.keras.optimizers.Adam(beta_1=0.9, beta_2=0.999,learning_rate=1e-3)\n",
    "#metrics\n",
    "difrint_loss_tracker = tf.keras.metrics.Mean(name=\"difrint_loss\")\n",
    "unet_loss_tracker = tf.keras.metrics.Mean(name=\"unet_loss\")\n",
    "\n",
    "def loss_function(f1,f2):\n",
    "        l1 = tf.reduce_mean(tf.abs(f1 - f2))\n",
    "        #vgg loss\n",
    "        features_1 = vgg(f1)\n",
    "        features_2 = vgg(f2)\n",
    "        features_1 = tf.reshape(features_1,[-1]) #flatten tensor\n",
    "        features_2 = tf.reshape(features_2,[-1]) #flatten tensor\n",
    "        vgg_loss = tf.sqrt(tf.reduce_sum(tf.square(features_1 - features_2)))\n",
    "        return l1 + vgg_loss\n",
    "\n",
    "@tf.function\n",
    "def train_step(data):\n",
    "    f1,fs,fi,f2 = data\n",
    "    with tf.GradientTape() as tape, tf.GradientTape() as u_tape:\n",
    "        fint , fout = difrint([f1,fs,fi,f2])\n",
    "        loss = loss_function(fs,fout)\n",
    "        u_loss = loss_function(fs,fint)\n",
    "    grads = tape.gradient(loss, difrint.trainable_weights)\n",
    "    u_grads = u_tape.gradient(u_loss, unet.trainable_weights)\n",
    "    \n",
    "    optimizer.apply_gradients(\n",
    "        zip(grads,difrint.trainable_weights)\n",
    "    )\n",
    "    u_optimizer.apply_gradients(\n",
    "        zip(u_grads,unet.trainable_weights)\n",
    "    )\n",
    "\n",
    "    #update trackers\n",
    "    difrint_loss_tracker.update_state(loss)\n",
    "    unet_loss_tracker.update_state(u_loss)\n",
    "    return{\n",
    "        'difrint_loss': difrint_loss_tracker.result(),\n",
    "        'unet_loss': unet_loss_tracker.result() \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = FrameGenerator('D:/Files/Datasets/DAVIS-data/DAVIS/JPEGImages/480p/',(256,256))\n",
    "for [f1,fi,fs,f2] in data_gen():\n",
    "    cv2.imshow('window',cv2.hconcat([f1,fs]))\n",
    "    sleep(1/30)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = FrameGenerator('D:/Files/Datasets/DAVIS-data/DAVIS/JPEGImages/480p/',(256,256))\n",
    "output_signature = (tf.TensorSpec(shape = (None, None, 3), dtype = tf.float32),\n",
    "                    tf.TensorSpec(shape = (None, None, 3), dtype = tf.float32),\n",
    "                    tf.TensorSpec(shape = (None, None, 3), dtype = tf.float32),\n",
    "                    tf.TensorSpec(shape = (None, None, 3), dtype = tf.float32)\n",
    "                    )\n",
    "train_ds = tf.data.Dataset.from_generator(data_gen,\n",
    "                                          output_signature = output_signature)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.batch(1)\n",
    "train_ds = train_ds.cache('./Difrint Cache/').prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 6\tdifrint_loss: 1792.6521\tunet_loss: 1793.8043"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    for idx,batch in enumerate(train_ds):\n",
    "        loss_dict = train_step(batch)\n",
    "        if epoch >= 100:\n",
    "            optimizer.learning_rate *= 0.1\n",
    "            u_optimizer.learning_rate *- 0.1\n",
    "        print(f\"\\rbatch: {idx}\\tdifrint_loss: {loss_dict['difrint_loss']:.4f}\\tunet_loss: {loss_dict['unet_loss']:.4f}\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
